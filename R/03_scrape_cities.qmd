# Scrape Cities

This notebook scrapes the featured cities in the website. The cities are grouped into the Travel Regions.

## Initialize

Load the necessary packages as well as functions used across the project.

```{r}
#| label: initialize

library(tidyverse)
library(httr2)
library(rvest)
library(janitor)
library(DBI)

source("R/functions/scraping.R")

con = dbConnect(duckdb::duckdb(), "duck.db")
dbListTables(con) |> as_tibble_col("tables")
```

## Travel Regions

The Travel Regions page is a homepage to all of the featured cities in the website. Each of the cities are grouped within a Travel Region.

```{r}
homepage_url = "https://wvtourism.com/places-to-go/travel-regions/"
homepage_req = get_request(homepage_url)
homepage_resp = req_perform(homepage_req)

print(homepage_resp)

homepage_info = extract_homepage_info(homepage_resp) |> 
  rename(homepage = title) |> 
  mutate(url = homepage_url)

print(homepage_info)
dbWriteTable(con, "homepages", homepage_info, append = TRUE)
```

Now we need to extract the links for the Travel Regions, which will eventually lead to the Cities. We will also extract the page descriptions like we did for Groups and Categories.

```{r}
travel_regions_urls = homepage_resp |>
  resp_body_html() |> 
  html_element("ul.ttd") |> 
  html_children() |> 
  html_children() |> 
  html_attrs() |> 
  as_tibble_col() |> 
  unnest_wider(value) |> 
  select(travel_region = title, url = href)

print(travel_regions_urls)

travel_regions_reqs = travel_regions_urls |> 
  pull(url) |> 
  map(get_request)

travel_regions_resps = travel_regions_reqs |> 
  req_perform_sequential(on_error = "continue")

travel_regions_resps_failures = resps_failures(travel_regions_resps) |> print()
travel_regions_resps_successes = resps_successes(travel_regions_resps) |> print()

travel_regions = travel_regions_resps_successes |> 
  map(extract_homepage_info) |> 
  list_rbind() |> 
  rename(travel_region = title) |> 
  left_join(travel_regions_urls, join_by(travel_region))

print(travel_regions)
dbWriteTable(con, "travel_regions", travel_regions)
```

## Cities

Now that we have the Travel Regions pages, we can extract the Cities from within. This will be very similar to the workflow above, but we will need to extract more information from the City pages.

```{r}
cities_urls = travel_regions_resps_successes |> 
  map(extract_cities_urls) |> 
  list_rbind() |> 
  mutate( # Summersville & Hinton need fixes
    city = city |> 
      str_remove("Places To Go") |> 
      str_remove_all("\\d") |> 
      str_squish() |> 
      str_to_title()) 

print(cities_urls)

cities_reqs = cities_urls |> 
  pull(url) |> 
  map(get_request)

cities_resps = cities_reqs |> 
  req_perform_sequential(on_error = "continue")

cities_resps_failures = resps_failures(cities_resps) |> print()
cities_resps_successes = resps_successes(cities_resps) |> print()

cities = cities_resps_successes |> 
  map(extract_city_info) |> 
  list_rbind() |> 
  mutate(
    city = city |> 
      str_remove(fixed(" Convention & Visitors Bureau (CVB)")) |> 
      str_remove(fixed(" Convention and Visitors Bureau (CVB)")) |> 
      str_remove(fixed(" / Berkeley")) |> 
      str_remove(fixed("Greater ")),
    description = if_else(
      str_detect(description, "\\n"), 
      str_remove(description, ".*\\n"), 
      description),
    across(where(is.character), str_squish)) |> 
  clean_names() |> 
  left_join(cities_urls, join_by(city)) |> 
  select(travel_region, city, everything())

print(cities)
dbWriteTable(con, "cities", cities)
```

## Finalize

Let's look at the tables we've created so far.

```{r}
dbListTables(con) |> 
  map(\(table) dbReadTable(con, table) |> as_tibble()) |> 
  set_names(dbListTables(con))
```

Everything looks good so we will close the DB connection.

```{r}
dbDisconnect(con)
```
